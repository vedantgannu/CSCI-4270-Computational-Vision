# -*- coding: utf-8 -*-
"""hw5_SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xu4IiXxzGKh0f-zgHQj0RuurDiM4HUX0
"""

import numpy as np
import os
from sklearn.svm import LinearSVC
from sklearn.preprocessing import StandardScaler
from sklearn.utils import shuffle
from sklearn.metrics import confusion_matrix, f1_score
from sklearn.model_selection import GridSearchCV
from google.colab import files
import pickle

X_train = []
Y_train = []
X_valid = []
Y_valid = []
X_test = []
Y_test = []
X_train_shuffle = None
Y_train_shuffle = None
X_valid_standard = None
X_test_standard = None

def trainClassifiers():
	#5 Binary Classifers approach
	global X_train
	global Y_train
	global X_valid
	global Y_valid
	global X_test
	global Y_test
	global X_valid_standard
	global X_test_standard

	global X_train_shuffle
	global Y_train_shuffle
	classes = {
			"grass": [1, -1, -1, -1, -1]
			, "ocean": [-1, 1, -1, -1, -1]
			, "redcarpet": [-1, -1, 1, -1, -1]
			, "road": [-1, -1, -1, 1, -1]
			, "wheatfield": [-1, -1, -1, -1, 1]
	}
	#Aggregating training data
	#Data Structure:
	#Features....y0,y1,y2,y3,y4
	for training_file in os.listdir("/content/training"):
		data = np.load(os.path.join("/content/training", training_file))
		X_train += (data["arr_0"].tolist())
		Y_train += (len(data["arr_0"]) * [classes[training_file.split("_")[1].split(".")[0]]] )


	#Aggregating validation data
	for valid_file in os.listdir("/content/validation"):
		data = np.load(os.path.join("/content/validation", valid_file))
		X_valid += (data["arr_0"].tolist())
		Y_valid += (len(data["arr_0"]) * [classes[valid_file.split("_")[1].split(".")[0]]] )

	#Aggregating testing data
	for test_file in os.listdir("/content/test"):
		data = np.load(os.path.join("/content/test", test_file))
		X_test += (data["arr_0"].tolist())
		Y_test += (len(data["arr_0"]) * [classes[test_file.split("_")[1].split(".")[0]]] )


	X_train = np.array(X_train)
	Y_train = np.array(Y_train)
	X_valid = np.array(X_valid)
	Y_valid = np.array(Y_valid)
	X_test = np.array(X_test)
	Y_test = np.array(Y_test)

	X_train_shuffle, Y_train_shuffle = shuffle(X_train, Y_train, n_samples=len(X_train))

	scaler = StandardScaler()
	X_train_shuffle = scaler.fit_transform(X_train_shuffle)
	scaler = StandardScaler()

	X_valid_standard = scaler.fit_transform(X_valid)
	scaler = StandardScaler()

	X_test_standard = scaler.fit_transform(X_test)

	parameters = {"dual":[False], "max_iter":[1000], "tol":[0.001]
				,"C":[0.1, 0.5, 1, 5, 10]}
	svc_grass = LinearSVC()
	clf_grass = GridSearchCV(svc_grass, parameters)
	svc_ocean = LinearSVC()
	clf_ocean = GridSearchCV(svc_ocean, parameters)
	svc_redcarpet = LinearSVC()
	clf_redcarpet = GridSearchCV(svc_redcarpet, parameters)
	svc_road = LinearSVC()
	clf_road = GridSearchCV(svc_road, parameters)
	svc_wheatfield = LinearSVC()
	clf_wheatfield = GridSearchCV(svc_wheatfield, parameters)

	print("Training Grass classifier model on X_train: {} descriptors".format(len(X_train_shuffle)))
	#clf = LinearSVC(dual=False, multi_class="ovr", max_iter=2000, tol=0.001)
	clf_grass.fit(X_train_shuffle, Y_train_shuffle[:,0])
	pickle_model = "GridSearchCV_Grass.pkl"
	with open(pickle_model, 'wb') as file:
		pickle.dump(clf_grass, file)
	files.download(pickle_model)

	print("Training Ocean classifier model on X_train: {} descriptors".format(len(X_train_shuffle)))
	#clf = LinearSVC(dual=False, multi_class="ovr", max_iter=2000, tol=0.001)
	clf_ocean.fit(X_train_shuffle, Y_train_shuffle[:,1])
	pickle_model = "GridSearchCV_Ocean.pkl"
	with open(pickle_model, 'wb') as file:
		pickle.dump(clf_ocean, file)
	files.download(pickle_model)

	print("Training RedCarpet classifier model on X_train: {} descriptors".format(len(X_train_shuffle)))
	#clf = LinearSVC(dual=False, multi_class="ovr", max_iter=2000, tol=0.001)
	clf_redcarpet.fit(X_train_shuffle, Y_train_shuffle[:,2])
	pickle_model = "GridSearchCV_RedCarpet.pkl"
	with open(pickle_model, 'wb') as file:
		pickle.dump(clf_redcarpet, file)
	files.download(pickle_model)

	print("Training Road classifier model on X_train: {} descriptors".format(len(X_train_shuffle)))
	#clf = LinearSVC(dual=False, multi_class="ovr", max_iter=2000, tol=0.001)
	clf_road.fit(X_train_shuffle, Y_train_shuffle[:,3])
	pickle_model = "GridSearchCV_Road.pkl"
	with open(pickle_model, 'wb') as file:
		pickle.dump(clf_road, file)
	files.download(pickle_model)

	print("Training Wheatfield classifier model on X_train: {} descriptors".format(len(X_train_shuffle)))
	#clf = LinearSVC(dual=False, multi_class="ovr", max_iter=2000, tol=0.001)
	clf_wheatfield.fit(X_train_shuffle, Y_train_shuffle[:,4])
	pickle_model = "GridSearchCV_Wheatfield.pkl"
	with open(pickle_model, 'wb') as file:
		pickle.dump(clf_wheatfield, file)
	files.download(pickle_model)


def evalValidationData():
	#Evaluating Individual Classifier Accuracies on Validation set
	print("Individual Accuracies (Validation):")
	with open("/content/GridSearchCV_Grass.pkl", "rb") as model:
		clf1 = pickle.load(model)
		svm_grass = clf1.best_estimator_
		print("Grass:")
		print(clf1.cv_results_["mean_test_score"])
		print(svm_grass)
		Y_valid_predict = svm_grass.predict(X_valid_standard)
		print("Accuracy: ", (Y_valid[:,0] == Y_valid_predict).sum() / len(Y_valid_predict) *100)


	with open("/content/GridSearchCV_Ocean.pkl", "rb") as model:
		clf1 = pickle.load(model)
		svm_ocean = clf1.best_estimator_
		print("Ocean:")
		print(clf1.cv_results_["mean_test_score"])
		print(svm_ocean)
		Y_valid_predict = svm_ocean.predict(X_valid_standard)
		print("Accuracy: ", (Y_valid[:,1] == Y_valid_predict).sum() / len(Y_valid_predict) *100)

	with open("/content/GridSearchCV_RedCarpet.pkl", "rb") as model:
		clf1 = pickle.load(model)
		svm_redcarpet = clf1.best_estimator_
		print("RedCarpet:")
		print(clf1.cv_results_["mean_test_score"])
		print(svm_redcarpet)
		Y_valid_predict = svm_redcarpet.predict(X_valid_standard)
		print("Accuracy: ", (Y_valid[:,2] == Y_valid_predict).sum() / len(Y_valid_predict) *100)

	with open("/content/GridSearchCV_Road.pkl", "rb") as model:
		clf1 = pickle.load(model)
		svm_road = clf1.best_estimator_
		print("Road:")
		print(clf1.cv_results_["mean_test_score"])
		print(svm_road)
		Y_valid_predict = svm_road.predict(X_valid_standard)
		print("Accuracy: ", (Y_valid[:,3] == Y_valid_predict).sum() / len(Y_valid_predict) *100)

	with open("/content/GridSearchCV_Wheatfield.pkl", "rb") as model:
		clf1 = pickle.load(model)
		svm_wheatfield = clf1.best_estimator_
		print("Wheatfield:")
		print(clf1.cv_results_["mean_test_score"])
		print(svm_wheatfield)
		Y_valid_predict = svm_wheatfield.predict(X_valid_standard)
		print("Accuracy: ", (Y_valid[:,4] == Y_valid_predict).sum() / len(Y_valid_predict) *100)


def evalTestingData():
	#Evaluating Individual Classifier Accuracies on Testing set
	print("Individual Accuracies (Test):")
	with open("/content/GridSearchCV_Grass.pkl", "rb") as model:
		clf1 = pickle.load(model)
		svm_grass = clf1.best_estimator_
		print("Grass:")
		print(svm_grass)
		Y_test_predict = svm_grass.predict(X_test_standard)
		print("Accuracy: ", (Y_test[:,0] == Y_test_predict).sum() / len(Y_test_predict) *100)


	with open("/content/GridSearchCV_Ocean.pkl", "rb") as model:
		clf1 = pickle.load(model)
		svm_ocean = clf1.best_estimator_
		print("Ocean:")
		print(svm_ocean)
		Y_test_predict = svm_ocean.predict(X_test_standard)
		print("Accuracy: ", (Y_test[:,1] == Y_test_predict).sum() / len(Y_test_predict) *100)

	with open("/content/GridSearchCV_RedCarpet.pkl", "rb") as model:
		clf1 = pickle.load(model)
		svm_redcarpet = clf1.best_estimator_
		print("RedCarpet:")
		print(svm_redcarpet)
		Y_test_predict = svm_redcarpet.predict(X_test_standard)
		print("Accuracy: ", (Y_test[:,2] == Y_test_predict).sum() / len(Y_test_predict) *100)

	with open("/content/GridSearchCV_Road.pkl", "rb") as model:
		clf1 = pickle.load(model)
		svm_road = clf1.best_estimator_
		print("Road:")
		print(svm_road)
		Y_test_predict = svm_road.predict(X_test_standard)
		print("Accuracy: ", (Y_test[:,3] == Y_test_predict).sum() / len(Y_test_predict) *100)

	with open("/content/GridSearchCV_Wheatfield.pkl", "rb") as model:
		clf1 = pickle.load(model)
		svm_wheatfield = clf1.best_estimator_
		print("Wheatfield:")
		print(svm_wheatfield)
		Y_test_predict = svm_wheatfield.predict(X_test_standard)
		print("Accuracy: ", (Y_test[:,4] == Y_test_predict).sum() / len(Y_test_predict) *100)

	#Compute Validation Set Confusion Matrix by finding best classifier score for each image descriptor
	score0 = (svm_grass.coef_ @ X_valid_standard.T) + svm_grass.intercept_
	score1 = (svm_ocean.coef_ @ X_valid_standard.T) + svm_ocean.intercept_
	score2 = (svm_redcarpet.coef_ @ X_valid_standard.T) + svm_redcarpet.intercept_
	score3 = (svm_road.coef_ @ X_valid_standard.T) + svm_road.intercept_
	score4 = (svm_wheatfield.coef_ @ X_valid_standard.T) + svm_wheatfield.intercept_

	best_classifier = np.argmax(np.concatenate((score0, score1, score2, score3, score4), axis=0).T, axis=1)
	print("Validation:")
	print(confusion_matrix(y_true=np.argmax(Y_valid, axis=1), y_pred=best_classifier))
  

if __name__ == "__main__":
  trainClassifiers()
  evalValidationData()
  evalTestingData()
  
  



